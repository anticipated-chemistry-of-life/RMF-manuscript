\documentclass[a4paper,11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage{xcolor} % Required for specifying custom colours
\usepackage[colorinlistoftodos]{todonotes}

\colorlet{mdtRed}{red!50!black}
\hypersetup{
	colorlinks,
	citecolor=mdtRed,
	filecolor=black,
	linkcolor=mdtRed,
	urlcolor=mdtRed
}
\usepackage{color}
\usepackage{graphicx}
\usepackage{lineno} % for line numbering
\usepackage{setspace} % for double-spaced text
\usepackage{soul}                 % optional; pdfcomment would pull it anyway
\sethlcolor{yellow}               % or any color you like (background)
\newcommand{\alert}[1]{\textcolor{red}{#1}}  % for red *text* instead of highlight
\usepackage[left=2.5cm, right=2.5cm, top=3cm, bottom=3cm]{geometry} % for margins
\usepackage{tikz}
\usetikzlibrary{arrows.meta, calc, fit, tikzmark, bayesnet}
\usepackage{amsmath,amsfonts}
\usepackage{bbm}
\usepackage{authblk}
\usepackage{sidecap}
\sidecaptionvpos{figure}{t}
\usepackage[labelfont=bf,font={it}]{caption}
\usepackage[author={Default Reviewer}]{pdfcomment}


\setcounter{figure}{-1}


%%%%%%%%%%%%%%%%
% MATH SYMBOLS
%%%%%%%%%%%%%%%%
\DeclareMathOperator{\Poisson}{Poisson}
\DeclareMathOperator{\Multinom}{Multinom}
\DeclareMathOperator{\logit}{logit}
\DeclareMathOperator{\cov}{cov}
\DeclareMathOperator{\Ind}{I}
\def\P{\mathbb{P}}
\def\E{\mathbb{E}}

\def\x{\boldsymbol{x}}

\def\balpha{\boldsymbol{\alpha}}
\def\btau{\boldsymbol{\tau}}
\def\bmu{\boldsymbol{\mu}}
\def\bxi{\boldsymbol{\xi}}

\def\bLambda{\boldsymbol{\Lambda}}
\def\bP{\boldsymbol{P}}
\def\bd{\boldsymbol{d}}


\def\Ccal{{\cal C}}
\def\C{{\cal C}}
\def\E{{\cal E}}
\def\I{{\cal I}}
\def\N{{\cal N}}
\def\M{{\cal M}}
\def\R{{\cal R}}
\def\T{{\cal T}}
\def\X{{\cal X}}
\def\Y{{\cal Y}}
\def\Z{{\cal Z}}
\def\D{{\cal D}}

%%%%%%%%%%%%%%%%
% References
%%%%%%%%%%%%%%%%

\usepackage[style=numeric,natbib=true,doi=true,isbn=false,url=false,uniquename=false,uniquelist=false,firstinits=true,bibencoding=utf8,sorting=none]{biblatex}
\AtEveryBibitem{\clearfield{month}}
\AtEveryCitekey{\clearfield{month}}
\AtEveryBibitem{\clearfield{pages}}
\AtEveryCitekey{\clearfield{pages}}
\AtEveryBibitem{\clearfield{archivePrefix}}
\AtEveryCitekey{\clearfield{archivePrefix}}
\AtEveryBibitem{\clearfield{arxivId}}
\AtEveryCitekey{\clearfield{arxivId}}
\AtEveryBibitem{\clearfield{eprint}}
\AtEveryCitekey{\clearfield{eprint}}


\DeclareNameFormat{newformat}{%
	\nameparts{#1}% split the name data, will not be necessary in future versions
	\usebibmacro{name:newformat}%
}

\bibliography{library.bib}
\setlength\parindent{0pt}
%\linenumbers

%%%%%%%%%%%%%%%%
% Opening
%%%%%%%%%%%%%%%%

\title{Annual Report Year 1 \\
	Anticipating the Chemistry of Life (ACOL)}

\date{\today} % Remove date
\author[1,2]{Marco Visani}
\affil[1]{Department of Biology, University of Fribourg, 1700 Fribourg, Switzerland}
\affil[2]{Swiss Institute of Bioinformatics, 1700 Fribourg, Switzerland}

\begin{document}

\maketitle

\tableofcontents

\section{Introduction}
Public databases compiling genes (e.g., GenBank) and proteins (e.g., UniProt) have long been essential resources for the life sciences. Until recently, no equivalent resource existed for small molecules and their producing organisms. The LOTUS\cite{rutzLOTUSInitiativeOpen2022} project was designed to address this issue, and forms currently the most comprehensive collection of natural products (NP) occurrences. It however\pdfmarkupcomment[author={PMA},markup=Highlight,color={red}]{ }{miss: mostly}gathers compounds physically isolated from species.\pdfmarkupcomment[author={PMA},markup=Highlight,color={yellow}]{ While this ensures high confidence, the process of extraction and isolation is too slow to realistically document the chemical diversity of life.}{You can also mention and briefly describe the publication bias (only new and / or bioactive NPs are published)} To address this issue, we explore two directions: experimental and computational. On one side, the \pdfmarkupcomment[author={PMA},markup=Highlight,color={yellow}]{Earth Metabolome Initiative}{add hyperlink to website, ressources and tools as much as possible. Linked Open Data starts by these small steps} will establish an open, linked knowledge base documenting the metabolome of all living organisms. \pdfmarkupcomment[author={PMA},markup=Highlight,color={yellow}]{In parallel,}{Here this is too abrupt. Its great that you have followed the CNTO structures. You can also do it within a paragraph. E.g. in this case you said why we did LOTUS then why we do EMI. You have to detail more on why we do ACOL. EMI will be lenghty, takes decades, cost millions ... among others.} we develop computational strategies to anticipate the chemical constitution of species based on prior knowledge.

My PhD work focuses on developing a probabilistic model that integrates the knowledge from LOTUS with large-scale mass spectrometry datasets to predict species metabolomes and estimate the likelihood of encountering specific natural products across the tree of life. After training and validation, the model should be able to predict the probability of finding a given molecule in a given species, even if that compound has never been experimentally detected in it before.

\section{Markov Random Field}

\subsection{WP 1}
We assume that the pattern of presence and absence of molecules in species is described by similarities within each dimension. For instance, closely related species may share a similar set of NPs and NPs related in their synthesis may share a similar distribution across species. To model such similarities, we adopt a \href{https://en.wikipedia.org/wiki/Markov_random_field}{Markov Random Field} (MRF) approach.

The first months of my PhD were dedicated to developing the technical skills to implement this model. To develop my \textit{C++} programming skills, I started by creating basic model components such as bitwise operations, class design and \textit{C++} best practices. I also familiarized myself with \pdfmarkupcomment[author={PMA},markup=Highlight,color={yellow}]{the software tools available in Daniel Wegmann's lab.}{is there a repo or a list of these. Which ones in particular ?}

Once the first version of the model was implemented, we performed some simulations to evaluate whether the inference procedure could accurately recover known parameters from synthetic data. These simulations revealed some issues in the inference, which led to some modifications. In particular, we changed the rate matrix to depend on a single parameter $\alpha_c$, representing \pdfmarkupcomment[author={PMA},markup=Highlight,color={yellow}]{the rate of change from a $0$ to a $1$:}{overall this is also quite abrupt. YOu should reallytake the reader by the hand. Typically I would have a small tree diagram were you illustrate this concept of rate of change.}


\begin{equation}
	\bLambda_c =
	\begin{pmatrix}
		-\alpha_c  & \alpha_c    \\
		1-\alpha_c & \alpha_c -1 \\
	\end{pmatrix}
	\label{eq:rate matrix}
\end{equation}

This modification adjusts the transition probabilities between a parent node $p(n)$ and its child $n$ as follows:
\begin{equation}
	\bP(n) = \exp(\bLambda_c \nu_c b(n)).
\end{equation}

From this, the stationary distribution of the root state is derived as:
\begin{equation}
	\bP_{\infty} = \left(1-\alpha_c, \alpha_c\right).
	\label{eq:stationary distribution}
\end{equation}

To improve the robustness of the model against observational noise, we also introduced an error rate parameter $\epsilon$ \pdfmarkupcomment[author={PMA},markup=Highlight,color={yellow}]{such that:}{would be worth traducing in lay terms what are the four cases. E.g. case 1 \epsilon is the probability of observing a molecule when it is not present ... etc}
\begin{equation}
	\P(L_{ms}|\x(m,s), R_{ms}) =
	\begin{cases}
		\epsilon \quad   & \mathrm{if\ } \x(m,s)=0, L_{ms} = 1, \\
		1-\epsilon \quad & \mathrm{if\ } \x(m,s)=0, L_{ms} = 0, \\
		R_{ms} \quad     & \mathrm{if\ } \x(m,s)=1, L_{ms} = 1, \\
		1- R_{ms} \quad  & \mathrm{if\ } \x(m,s)=1, L_{ms} = 0.
	\end{cases}
\end{equation}

Finally, the probability of discovery $R_{ms}$ was redefined as:
\begin{equation}
	R_{ms} = (1 - e^{-\gamma_0 P_m })  (1 - e^{-\gamma_1 Q_s})
\end{equation}

\pdfmarkupcomment[author={PMA},markup=Highlight,color={yellow}]{Overall, the objectives defined in the first work package (WP1) were achieved within the expected time frame: we now have a first working implementation of the MRF model that can simulate and infer molecule-species occurrence patterns.}{This seems very optimistic as a statement given what we have in hands at the moment no ? I am thinking in particular about the two cases of simulation of the Asterales and Asteraceae set ... The TAC is really the place to discuss current issues and clocking steps not (only) to show what worked.}


\subsection{WP 2}

The second work package focuses on modeling and integrating mass spectrometry (MS) data into the model developed in WP1. Mass spectrometry is a key source of experimental evidence for chemical composition and metabolite identification. \pdfmarkupcomment[author={PMA},markup=Highlight,color={yellow}]{Integrating such data into the model is essential to link computational predictions with real-world observations and to refine estimates of molecular occurrence across species.}{Notably for the throughput and number of annotation + possibility to repeat multiple times acquisition on the same extracts. This is waht makes this approach and resulting data so interesting compared to LOTUS data. In other words we need both and here, in the case of LCMS, exchange confidence in annotations with coverage.}

We initially \pdfmarkupcomment[author={PMA},markup=StrikeOut,color=red]{explored}{envisioned (not sure we really explored it or ?)} the use of ViMMS\cite{wandyViMMSFrameworkDevelop2022}, a simulation tool for MS data, as a potential way to model experimental variability and generate realistic spectra. However, after several discussions with Daniel and Pierre-Marie, we concluded that this approach would not fully meet our objectives. Specifically, ViMMS focuses on simulating acquisition processes, whereas our goal is to incorporate \textit{interpreted} spectral information—i.e., molecular annotations—into the probabilistic model.

We therefore decided to shift direction toward directly integrating the outputs and scores produced by existing annotation tools such as SIRIUS \cite{duhrkopSIRIUS4Rapid2019}, MetFrag \cite{ruttkiesMetFragRelaunchedIncorporating2016}, and CFM-ID \cite{wangCFMIDMoreAccurate2021}. These tools provide complementary estimates of molecular identity and structural similarity, which can be combined probabilistically to represent confidence in compound–spectrum assignments. Using only the scores from these methods, rather than relying on any single tool, would make the approach more flexible and robust to future methodological improvements.

\pdfmarkupcomment[author={PMA},markup=Highlight,color={yellow}]{At this stage, the specific implementation strategy is still under discussion. Our plan for the coming year is to integrate and weight the outputs of multiple annotation tools, allowing the MRF model to incorporate MS-based evidence in a consistent and scalable way.}{You focuss here on the last part (i.e. metabolite annotation. Yopu do not mention that the idea is to model the \textit{whole} LCMS process, what do we loose at the extraction step, at the lc step, at the ionization step etc...)}


\subsection{Artificial Extract}
As stated in the grant, we would like to model and include in the Markov Random Field, the potential \textit{loss} of molecules during the experimental process from their presence in Nature to their identification by mass spectrometry (\textit{i.e.} extraction, liquid chromatography, and mass spectrometry fragmentation).
\pdfmarkupcomment[author={PMA},markup=Highlight,color={yellow}]{To achieve this, we have acquired a library of 550 pure natural products, which we plan to mix together to create a “artificial extract” that mimics the complexity of a biological sample. I am hoping that this controlled setup will allow us to quantify molecular losses occurring throughout the process, enabling us to incorporate these biases into the MRF model.}{I see this artificial extract as a way to benckmark the ionization and metabolite annotation stages. We are not going to proceed to reextraction of this mix so it would only allows us to benchmark a part of the possible losses.} \pdfcomment[author={PMA},color=orange,icon=Note]{While commenting on this issue I realize that we actully want to model losses of molecules but also additions of molecules (notably ions, in source fragments and other degenerted features)}

In addition to the artificial extract experiment, we aim to analyze each pure compound individually using mass spectrometry. \pdfmarkupcomment[author={PMA},markup=Highlight,color={yellow}]{So far, plate 1 has been successfully processed.}{You should resume Jade's bachelor work here. Also mention that you have coached her during these monthes. I would have at least a table of results on plate + associated Venn plots what do we see in pos, neg, both, none etc.} \pdfmarkupcomment[author={PMA},markup=Highlight,color={yellow}]{Plate 3, previously analyzed by a bachelor student, produced inconsistent results and will therefore be reanalyzed.}{How so ? Do you have results comparing plate 1 and 3 ? Do you have summary of 1 + 3 ?} The remaining plates will also be measured and analyzed in the coming weeks or months.

\section{LOTUS Expanded\pdfcomment[author={PMA},color=orange,icon=Note]{You do not cite nor mention MINES in the paragraph.}}

One of the side projects of my PhD involves the \textit{in silico} expansion of the molecular space covered by LOTUS. The LOTUS database contains experimentally verified natural products, but it only represents a fraction of the chemical diversity that likely exists in nature. To better capture this diversity, we aim to generate new, hypothetical molecules that are chemically plausible yet not currently documented in LOTUS. \pdfmarkupcomment[author={PMA},markup=Highlight,color={yellow}]{The goal of this task}{Also mention how you view that this side project can contribute to ACOl. Several possibilities of sinergy here ...} is to extend the known chemical space and thereby improve our capacity to annotate real mass spectrometry (MS) data.

To achieve this, \pdfmarkupcomment[author={PMA},markup=Highlight,color={yellow}]{we performed }{This is a follow-up of PAscal master thesis and should be mentionned.}an \textit{in silico} expansion starting from approximately $100'000$ compounds in LOTUS, generating a set of about $3 \cdot 10^6$ new molecular structures. These generated compounds can then be fragmented to produce an \textit{in silico} spectral database (ISDB), which can be compared with experimental data. This process should increase the number of possible annotations in real datasets and help us identify potential natural products that have not yet been reported.

As an initial validation, we compared the generated compounds with entries from COCONUT\cite{sorokinaCOCONUTOnlineCollection2021}, another large natural product database that does not include species occurrence information for all its compounds. \pdfmarkupcomment[author={PMA},markup=Highlight,color={yellow}]{About $17'000$ (0.57\%) of the \textit{in silico} molecules overlapped with structures in COCONUT, suggesting that the generation process can produce chemically realistic and biologically relevant compounds.}{Are that the figures after substarcting LOTUS from COCONUT ? You should add results as table, plot + link to code used to generate the figs.}

I also hope to identify some of the predicted molecules in newly published studies, such as those in the \textit{Journal of Natural Products}, which would provide empirical support for our chemical expansion approach. However, a major limitation is that most publications in this journal do not provide molecular structures in a machine-readable format, such as SMILES. This makes it difficult to perform rapid validation or to develop automated tools capable of detecting these compounds in the literature.

\section{EMI-Monorepo}

The \href{https://github.com/earth-metabolome-initiative/emi-monorepo}{EMI-Monorepo} is a Rust-based monolithic repository that hosts all software tools developed for the Earth Metabolome Initiative. The project is led by our postdoctoral researcher, Luca, who supervises the development of the entire platform—from backend and frontend components to data analysis modules. Building the infrastructure in Rust ensures high performance, reliability, and scalability, which are essential for handling large-scale metabolomics data.

Given the complexity of the portal, Luca occasionally assigns me specific tasks that serve both the project and my own training in Rust programming. This has allowed me to contribute to several (\textit{crates}) within the repository and to better understand the structure and design principles of the software. Over the past months, however, my involvement has decreased as I focused on other aspects of my PhD, and I have not coded in Rust recently.

In the coming year, I aim to re-engage with the EMI-Monorepo and further develop my expertise in Rust. Mastering this language is one of my personal objectives for the PhD. \pdfmarkupcomment[author={PMA},markup=Highlight,color={yellow}]{I believe that a dedicated chemical library—similar to RDKit but implemented in Rust—would be a valuable contribution to the scientific community and a meaningful way to advance my skills.}{You can mention Daniel Probst proposition + the existing rust crate dealing with rdkit}


\section{Frag-Graph}

Another side project I am exploring is what I call the \textit{fragmentation graph}. Existing tools such as SIRIUS use fragmentation trees to annotate molecules from mass spectra. These trees represent how a single molecule can fragment under specific conditions. However, I wondered whether it would be possible to generalize this concept by constructing a single, large \textit{fragmentation graph} that connects all molecules together through their potential fragmentation relationships.

In this approach, each input molecule is systematically fragmented by breaking all its bonds. The resulting fragments are considered as the molecule's children, and the full collection of molecules and fragments forms one single graph.

When analyzing a mass spectrum, we can then iterate over all nodes in the graph and check whether a fragment mass matches any of the observed peaks (within a defined tolerance). If a match is found, the corresponding intensity is assigned to that fragment and propagated to all its parent molecules in the graph.

\pdfmarkupcomment[author={PMA},markup=Highlight,color={yellow}]{Preliminary tests of this method have shown promising results.}{Maybe show some preliminary results. Also mention what approach you are using for the brute fragmentation.} \pdfmarkupcomment[author={PMA},markup=Highlight,color={yellow}]{In several cases, the correct molecule appears within the top 1 to 7 ranked candidates. Even when the top-ranked molecule is not the exact match, the highest-ranking candidates tend to be structurally similar to the true compound, which suggests that the method captures at least some chemical relationships.}{Here also for such statement please output a table, a plot and code + dataset used to generate them}

Given these interesting preliminary results, I am motivated to continue developing this approach and explore its potential as a tool for metabolite annotation. One of its main advantages is that it does not rely on machine learning; instead, the fragmentation rules can be iteratively refined should we ever want to. In the coming months, I plan to continue developing the tool and assess its performance against existing annotation tools.

\section{Perspectives}

\pdfmarkupcomment[author={PMA},markup=Highlight,color={yellow}]{In the coming year, I focus and continue working on the following aspects. 
}{I see a lot of focus overall on the side projects. Remind that they should remain what they are, hence side project. Please detail a bit more what you would see as next steps for the ACOL project it self. Even if these are not clear, even if they look sketch. This will be the occasion to discuss and plan for the next year.}

First, I will integrate MS/MS (MS2) data into the Markov Random Field (MRF) model and design a method for converting the outputs of various annotation tools (such as SIRIUS, MetFrag, and CFM-ID) into a format compatible with the MRF. This step is essential for linking experimental mass spectrometry evidence with computational predictions and for improving the model's accuracy in estimating molecular occurrences across species.

I also plan to complete and publish a short paper describing the \textit{LOTUS Expanded} project. Additional validation of the generated compounds is still required, but this work could provide valuable insights into the unexplored regions of natural product chemical space.

In parallel, I intend to continue developing my programming skills in Rust through contributions to the EMI-Monorepo. My goal is to progressively build small, modular cheminformatics libraries (\textit{crates}) that could later be integrated into the EMI platform, contributing to the broader open-source metabolomics community.

Finally, I plan to further investigate the \textit{Frag-Graph} concept, which has shown promising initial results for metabolite annotation. I will continue testing this approach, with the hopes of developing it into a functional annotation tool.

\printbibliography

\end{document}

% I am writing the annual report of my PhD in LaTex. I am required to summarize the progress made and outline the planned work for the next year in a written report of 3-4 pages. I've written the skeleton of the report and I want you to help me improve my grammar, make the sentences more coherent and fluid. Each section should always contain a context, a task and a need (why I do this, What I did, and what I'm planning to do). Make the sentences clear and simple. 
% I'll give you the sections one after each other. Here is one section : 
% ^^^^^^ Youhouuu :) Bonjour Marco ! Who are you talking to ? 
